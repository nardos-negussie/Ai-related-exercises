{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "import dlib  \n",
    "from scipy.spatial import distance as dist  \n",
    "from scipy.spatial import ConvexHull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = 'shape_predictor_68_face_landmarks.dat_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the parameters for the Dlib Face Detector and Face Landmark detector\n",
    "full_points = list(range(0,68))\n",
    "face_points = list(range(17,68))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the arrays that help us extract individual face landmarks \n",
    "#out of the 68 landmarks which Dlib returns\n",
    "JAWLINE_POINTS = list(range(0, 17))\n",
    "RIGHT_EYEBROW_POINTS = list(range(17, 22))\n",
    "LEFT_EYEBROW_POINTS = list(range(22, 27))\n",
    "NOSE_POINTS = list(range(27, 36))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "MOUTH_OUTLINE_POINTS = list(range(48, 61))\n",
    "MOUTH_INNER_POINTS = list(range(61, 68))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre-process the eye-overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the overlay image\n",
    "#the ‘-1’ parameter in cv2.imread is telling OpenCV to load the ‘Alpha Channel’ \n",
    "#(a.k.a. the transparency channel) of the image, along with the BGR channels\n",
    "im_eye = cv2.imread('0_l352CGq0WEF587uZ(1).png',  -1)\n",
    "\n",
    "#create a mask from the overlay\n",
    "\n",
    "orig_mask = im_eye[:,:,3] #take the alpha channel and create a mask from it\n",
    "\n",
    "#create inverted mask for the overlay\n",
    "orig_mask_inv = cv2.bitwise_not(orig_mask)\n",
    "\n",
    "#convert the overlay image to  BGR \n",
    "im_eye = im_eye[:,:,0:3]\n",
    "\n",
    "#save the original image size\n",
    "orig_height, orig_width = im_eye.shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  start capturing the frames from the Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cap():\n",
    "#     #initialize the webcam\n",
    "#     # Start capturing the WebCam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('Video', frame)\n",
    "        rects = detector(gray, 0)\n",
    "        for rect in rects:\n",
    "            x = rect.left()\n",
    "            y = rect.top()\n",
    "            x1 = rect.right()\n",
    "            y1 = rect.bottom()\n",
    "            landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])\n",
    "            left_eye = landmarks[LEFT_EYE_POINTS]\n",
    "            right_eye = landmarks[RIGHT_EYE_POINTS]\n",
    "    \n",
    "    break;\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to place the overlay on to the eyes of the face image, we need to find the size and the center of each of the eyes. We define a function in order to calculate them.\n",
    "We use the euclidean function to calculate the width of the eye, and the ConvexHull function to calculate the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_size(eye):\n",
    "    eyeWidth = dist.euclidean(eye[0], eye[3])\n",
    "    hull = ConvexHull(eye)\n",
    "    eyeCenter = np.mean(eye[hull.vertices, :], axis=0)\n",
    "    eyeCenter = eyeCenter.astype(int)\n",
    "    return int(eyeWidth), eyeCenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'left_eye' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5b24f7273e2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pass each of the eyes separately to get their sizes individually,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mleftEyeSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleftEyeCenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meye_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_eye\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrightEyeSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightEyeCenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meye_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_eye\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'left_eye' is not defined"
     ]
    }
   ],
   "source": [
    "# pass each of the eyes separately to get their sizes individually,\n",
    "leftEyeSize, leftEyeCenter = eye_size(left_eye)\n",
    "rightEyeSize, rightEyeCenter = eye_size(right_eye)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it’s time to place the overlay on to the face image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_eye(frame, eyeCenter, eyeSize):\n",
    "    eyeSize = int(eyeSize * 1.5)\n",
    "    x1 = int(eyeCenter[0,0] - (eyeSize/2))\n",
    "    x2 = int(eyeCenter[0,0] + (eyeSize/2))\n",
    "    y1 = int(eyeCenter[0,1] - (eyeSize/2))\n",
    "    y2 = int(eyeCenter[0,1] + (eyeSize/2))\n",
    "    h, w = frame.shape[:2]\n",
    "    # check for clipping\n",
    "    if x1 < 0:\n",
    "        x1 = 0\n",
    "    if y1 < 0:\n",
    "        y1 = 0\n",
    "    if x2 > w:\n",
    "        x2 = w\n",
    "    if y2 > h:\n",
    "        y2 = h\n",
    "    # re-calculate the size to avoid clipping\n",
    "    eyeOverlayWidth = x2 - x1\n",
    "    eyeOverlayHeight = y2 - y1\n",
    "    # calculate the masks for the overlay\n",
    "    eyeOverlay = cv2.resize(imgEye, (eyeOverlayWidth,eyeOverlayHeight), interpolation = cv2.INTER_AREA)\n",
    "    mask = cv2.resize(orig_mask, (eyeOverlayWidth,eyeOverlayHeight), interpolation = cv2.INTER_AREA)\n",
    "    mask_inv = cv2.resize(orig_mask_inv, (eyeOverlayWidth,eyeOverlayHeight), interpolation = cv2.INTER_AREA)\n",
    "    # take ROI for the verlay from background, equal to size of the overlay image\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    # roi_bg contains the original image only where the overlay is not, in the region that is the size of the overlay.\n",
    "    roi_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "    # roi_fg contains the image pixels of the overlay only where the overlay should be\n",
    "    roi_fg = cv2.bitwise_and(eyeOverlay,eyeOverlay,mask = mask)\n",
    "    # join the roi_bg and roi_fg\n",
    "    dst = cv2.add(roi_bg,roi_fg)\n",
    "    # place the joined image, saved to dst back over the original image\n",
    "    frame[y1:y2, x1:x2] = dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are basically doing here is \n",
    "  - calculate the size of the overlay,\n",
    "  - get a box of pixels of that size out of the face image around the position of where the overlay should go,\n",
    "  - substitute the pixels of that extracted box with the pixels from the overlay image excluding the transparent pixels (using the masks we calculate),\n",
    "  - and finally put the substituted box of pixels back in to the face image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'leftEyeCenter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a854f704343f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We need to do this for each eye individually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplace_eye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleftEyeCenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleftEyeSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplace_eye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightEyeCenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightEyeSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'leftEyeCenter' is not defined"
     ]
    }
   ],
   "source": [
    "# We need to do this for each eye individually\n",
    "place_eye(frame, leftEyeCenter, leftEyeSize)\n",
    "place_eye(frame, rightEyeCenter, rightEyeSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
